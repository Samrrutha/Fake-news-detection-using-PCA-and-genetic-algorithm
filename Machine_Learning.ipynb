{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "iaTs9w91J1wN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHQwq9keeoVt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSVs properly\n",
        "true_df = pd.read_csv(\"/content/True.csv\", encoding='utf-8')\n",
        "fake_df = pd.read_csv(\"/content/Fake.csv\", encoding='utf-8')\n",
        "# Keep only relevant columns if they exist\n",
        "columns_to_keep = ['title', 'text', 'subject', 'date']\n",
        "fake_df = fake_df[columns_to_keep]\n",
        "\n",
        "# Check the first few rows again\n",
        "print(\"True News Columns:\", true_df.columns)\n",
        "print(true_df.head())\n",
        "print(\"Fake News Columns:\", fake_df.columns)\n",
        "print(fake_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Anjuf08bHcZY"
      },
      "outputs": [],
      "source": [
        "true_df['label'] = 1\n",
        "fake_df['label'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_PIp23TIMiL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "merged_df = pd.concat([true_df, fake_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0iPXpkcHQva"
      },
      "outputs": [],
      "source": [
        "merged_df.info()\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfrIccJxLF3_"
      },
      "outputs": [],
      "source": [
        "merged_df['text_length'] = merged_df['text'].apply(lambda x: len(str(x)))\n",
        "merged_df['title_length'] = merged_df['title'].apply(lambda x: len(str(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3iO7UJkWHQS"
      },
      "source": [
        "**UNIVARIATE NON GRAPHICAL ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkCvHlmMMZ5U"
      },
      "outputs": [],
      "source": [
        "print(\"=== UNIVARIATE NON GRAPHICAL ANALYSIS ===\\n\")\n",
        "print(merged_df[['text_length', 'title_length']].describe())\n",
        "\n",
        "# Mode\n",
        "print(\"\\nMode of text length:\", merged_df['text_length'].mode()[0])\n",
        "print(\"Mode of title length:\", merged_df['title_length'].mode()[0])\n",
        "\n",
        "# Range\n",
        "print(\"\\nRange of text length:\", merged_df['text_length'].max() - merged_df['text_length'].min())\n",
        "print(\"Range of title length:\", merged_df['title_length'].max() - merged_df['title_length'].min())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RAPFWXtV_nW"
      },
      "source": [
        "**UNIVARIATE GRAPHICAL ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUL1wT1zNhcc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(merged_df['text_length'], bins=50, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Text Length')\n",
        "plt.xlabel('Text Length (Characters)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UynmXR1cNpUe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 5))\n",
        "sns.countplot(x='label', data=merged_df, palette='Set2')\n",
        "plt.title('Distribution of News Labels (Fake vs Real)')\n",
        "plt.xlabel('Label (0 = Fake, 1 = Real)')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks([0, 1], ['Fake', 'Real'])\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load both datasets\n",
        "true_df = pd.read_csv(\"/content/True.csv\")\n",
        "fake_df = pd.read_csv(\"/content/Fake.csv\")\n",
        "\n",
        "# Add labels: 1 for Real news, 0 for Fake news\n",
        "true_df['label'] = 1\n",
        "fake_df['label'] = 0\n",
        "\n",
        "# Combine both datasets into one\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True)\n",
        "\n",
        "# Create a new column for word count (using the 'text' column)\n",
        "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Calculate average word count for each class (0 = Fake, 1 = Real)\n",
        "avg_word_count = df.groupby('label')['word_count'].mean().reset_index()\n",
        "\n",
        "# Map labels to readable text\n",
        "avg_word_count['label'] = avg_word_count['label'].map({0: 'Fake News', 1: 'Real News'})\n",
        "\n",
        "# Plotting the bar plot\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x='label', y='word_count', data=avg_word_count, palette='Accent')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Average Word Count per Article by Class', fontsize=14)\n",
        "plt.xlabel('News Category')\n",
        "plt.ylabel('Average Word Count')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2_mpCAz-Jfip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load datasets\n",
        "true_df = pd.read_csv(\"/content/True.csv\")\n",
        "fake_df = pd.read_csv(\"/content/Fake.csv\")\n",
        "\n",
        "# Add labels\n",
        "true_df['label'] = 'Real News'\n",
        "fake_df['label'] = 'Fake News'\n",
        "\n",
        "# Combine the datasets\n",
        "df = pd.concat([true_df, fake_df], ignore_index=True)\n",
        "\n",
        "# Compute word count for each article\n",
        "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot histogram for word count distribution by class\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(data=df, x='word_count', hue='label', bins=50, kde=True, palette='Set2', alpha=0.7)\n",
        "\n",
        "plt.xlim(0, 2500)\n",
        "# Customize plot\n",
        "plt.title('Article Word Count Distribution', fontsize=16)\n",
        "plt.xlabel('Word Count per Article')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Show the plot\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OmqNddvAKk5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5k7NqTYOJQw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Filter the selected subjects (already done previously)\n",
        "valid_subjects = ['US_News', 'Government News', 'politicsNews', 'worldnews', 'News', 'politics']\n",
        "filtered_df = merged_df[merged_df['subject'].isin(valid_subjects)]\n",
        "\n",
        "# Step 2: Plot histogram (for categorical data)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(filtered_df['subject'], bins=len(valid_subjects), color='skyblue', edgecolor='black')\n",
        "plt.title('Histogram of Selected News Subjects')\n",
        "plt.xlabel('Subject')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK58rKcaNtLL"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot box plot for overall text_length distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(y=merged_df['text_length'], color='lightblue')\n",
        "plt.title('Box Plot of News Text Length')\n",
        "plt.ylabel('Text Length')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDymAXejTbMH"
      },
      "source": [
        "**MULTIVARIATE NON GRAPHICAL ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNDEfMYaRCvE"
      },
      "outputs": [],
      "source": [
        "# Summary statistics (mean, std, min, max, etc.)\n",
        "summary_stats = merged_df.describe()\n",
        "print(\"Summary Statistics:\\n\")\n",
        "print(summary_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjXCGWVNRQz0"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "correlation_table = merged_df.corr(numeric_only=True)\n",
        "print(\"\\nCorrelation Table:\\n\")\n",
        "print(correlation_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nchz-sYVTSTe"
      },
      "source": [
        "**MULTIVARIATE GRAPHICAL ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jMari24RlpO"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(merged_df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Heatmap of Numerical Feature Correlation\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLQz_5NQRoEW"
      },
      "outputs": [],
      "source": [
        "avg_length_per_subject = filtered_df.groupby('subject')['text_length'].mean().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x=avg_length_per_subject.index, y=avg_length_per_subject.values, palette='viridis')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel(\"Average Text Length\")\n",
        "plt.xlabel(\"Subject\")\n",
        "plt.title(\"Bar Chart: Average Text Length per Subject\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0et3QcgSmBi"
      },
      "outputs": [],
      "source": [
        "filtered_df['word_count'] = filtered_df['text'].apply(lambda x: len(str(x).split()))\n",
        "filtered_sample = filtered_df.sample(n=100, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAcUzTMrR2qW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Scatter plot\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(data=filtered_sample, x='word_count', y='text_length', hue='subject', alpha=0.6, s=75)\n",
        "plt.title(\"Scatter Plot: Text Length vs Word Count\")\n",
        "plt.xlabel(\"Word Count\")\n",
        "plt.ylabel(\"Text Length\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QiskUgtXC4k"
      },
      "source": [
        "# **DATA PREPARATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejpZNrz4XP4C"
      },
      "source": [
        "**Data cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUbceYfPfiww"
      },
      "source": [
        "**Removing dulpicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yitK12UUXLIq"
      },
      "outputs": [],
      "source": [
        "# Check how many duplicates exist\n",
        "print(\"Duplicate Rows Before:\", merged_df.duplicated().sum())\n",
        "\n",
        "# Remove duplicates\n",
        "merged_df = merged_df.drop_duplicates()\n",
        "\n",
        "# Verify removal\n",
        "print(\"Duplicate Rows After:\", merged_df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlLheIsjfojS"
      },
      "source": [
        "**Handling missing values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llKi4SDwXiVZ"
      },
      "outputs": [],
      "source": [
        "# Check missing values\n",
        "print(\"Missing Values:\\n\", merged_df.isnull().sum())\n",
        "merged_df['subject'] = merged_df['subject'].fillna(merged_df['subject'].mode()[0])\n",
        "merged_df['date'] = merged_df['date'].fillna('Unknown')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxm260LAfX-W"
      },
      "source": [
        "**Removing outliners**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_6g1EtfYUos"
      },
      "outputs": [],
      "source": [
        "def remove_outliers_iqr(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    # Keep only the values within bounds\n",
        "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "\n",
        "# Apply to each column one by one\n",
        "filtered_df = remove_outliers_iqr(filtered_df, 'text_length')\n",
        "filtered_df = remove_outliers_iqr(filtered_df, 'title_length')\n",
        "filtered_df = remove_outliers_iqr(filtered_df, 'word_count')\n",
        "\n",
        "# Check the new shape of the dataset\n",
        "print(\"Dataset shape after removing outliers:\", filtered_df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFxw-59pfyJc"
      },
      "source": [
        "**Data encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPHaHwJGfSWy"
      },
      "source": [
        "**One hot encoding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jvun6H1KeaDF"
      },
      "outputs": [],
      "source": [
        "# One-Hot Encoding the 'subject' column\n",
        "encoded_df = pd.get_dummies(filtered_df, columns=['subject'], drop_first=True)\n",
        "\n",
        "print(\"Dataset shape after encoding:\", encoded_df.shape)\n",
        "encoded_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkT-P6v-f_tm"
      },
      "source": [
        "**Data splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kvgf5uagTse"
      },
      "source": [
        "**Train and test split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWc8B0TCgEFo"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target label (y)\n",
        "X = filtered_df.drop(columns=['label', 'subject'])  # Exclude target and redundant columns\n",
        "y = filtered_df['label']  # or use 'label' if already encoded\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Print shape of datasets\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APE7zQcpgYPA"
      },
      "source": [
        "**Validation split**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWc7XeZ2gdkX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Features and Target\n",
        "X = filtered_df.drop(columns=['label', 'subject'])\n",
        "y = filtered_df['label']  # or 'label' if you're using the original target\n",
        "\n",
        "# Step 1: Split into Train+Val and Test\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 2: Split Train+Val into Train and Validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Show shapes\n",
        "print(\"Training Set Shape   :\", X_train.shape)\n",
        "print(\"Validation Set Shape :\", X_val.shape)\n",
        "print(\"Testing Set Shape    :\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b-x6vjxgrNC"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSIaz8JjgvGf"
      },
      "source": [
        "**Correlation matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDSexNVlgzp8"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check your actual available columns first\n",
        "print(filtered_df.columns)\n",
        "\n",
        "# Use only available numeric columns\n",
        "numeric_cols = ['title_length', 'word_count', 'subject_encoded']\n",
        "\n",
        "# Compute and plot correlation matrix\n",
        "corr_matrix = filtered_df[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix of Numeric Features\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA CLEANING**"
      ],
      "metadata": {
        "id": "Mi_72IRHKiYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "df_fake = pd.read_csv(\"/content/Fake.csv\")\n",
        "df_true = pd.read_csv(\"/content/True.csv\")\n",
        "\n",
        "# Check initial sizes\n",
        "# print(f\"Fake News Records: {len(df_fake)}\")\n",
        "# print(f\"True News Records: {len(df_true)}\")\n",
        "\n",
        "# Find the minimum count to balance\n",
        "min_count = min(len(df_fake), len(df_true))\n",
        "\n",
        "# Take equal number of records from both\n",
        "df_fake = df_fake.sample(n=min_count, random_state=42)\n",
        "df_true = df_true.sample(n=min_count, random_state=42)\n",
        "\n",
        "print(f\"Balanced Fake News Records: {len(df_fake)}\")\n",
        "print(f\"Balanced True News Records: {len(df_true)}\")\n",
        "\n",
        "# Add a label column\n",
        "df_fake[\"label\"] = \"fake\"\n",
        "df_true[\"label\"] = \"true\"\n",
        "\n",
        "# Combine datasets\n",
        "df_combined = pd.concat([df_fake, df_true], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Save combined dataset\n",
        "df_combined.to_csv(\"balanced_combined_data.csv\", index=False)\n",
        "\n",
        "print(\"Dataset balanced and combined successfully!\")\n",
        "print(f\"Total Records: {len(df_combined)}\")\n"
      ],
      "metadata": {
        "id": "_sGgebwoRiil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling missing values**"
      ],
      "metadata": {
        "id": "ACQTLDwSKkde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the combined dataset\n",
        "df = pd.read_csv(\"/content/balanced_combined_data.csv\")\n",
        "\n",
        "# Print total records before cleaning\n",
        "print(f\"Total Records Before Cleaning: {len(df)}\")\n",
        "\n",
        "# Fill missing values with an empty string\n",
        "df = df.fillna(\"\")\n",
        "\n",
        "# Print missing values after handling\n",
        "missing_values_after = df.isnull().sum().sum()\n",
        "print(f\" Total Missing Values After Handling: {missing_values_after}\")\n",
        "\n",
        "# Print total records after handling missing values\n",
        "print(f\"Total Records After Cleaning: {len(df)}\")\n",
        "\n",
        "# Save cleaned dataset\n",
        "df.to_csv(\"cleaned_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "uawd_9X4T4X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing Duplicates**"
      ],
      "metadata": {
        "id": "etQ-jYuKU-mS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate records\n",
        "duplicates_before = df.duplicated().sum()\n",
        "print(f\"Duplicates Before Removal: {duplicates_before}\")\n",
        "\n",
        "# Remove duplicates\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Check duplicates after removal\n",
        "duplicates_after = df.duplicated().sum()\n",
        "print(f\"Duplicates After Removal: {duplicates_after}\")\n",
        "\n",
        "# Save cleaned dataset\n",
        "df.to_csv(\"cleaned_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "wGUeo58FVDuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Outliers**"
      ],
      "metadata": {
        "id": "WjReMjMPVX4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# Select numerical columns\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Compute Z-scores\n",
        "df[num_cols] = df[num_cols].apply(zscore)\n",
        "\n",
        "# Remove outliers where Z-score > 3\n",
        "df_no_outliers = df[(df[num_cols] < 3).all(axis=1)]\n",
        "\n",
        "print(f\"Records Before Outlier Removal: {len(df)}\")\n",
        "print(f\"Records After Outlier Removal: {len(df_no_outliers)}\")\n",
        "\n",
        "# Save final cleaned dataset\n",
        "df_no_outliers.to_csv(\"cleaned_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "6_CfZPZsVaL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the cleaned dataset\n",
        "df_cleaned = pd.read_csv(\"final_cleaned_data.csv\", dtype=str, low_memory=False)\n",
        "\n",
        "# Check initial shape before removing duplicates\n",
        "print(f\"Initial Shape: {df_cleaned.shape}\")\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_cleaned = df_cleaned.drop_duplicates()\n",
        "\n",
        "# Check shape after removing duplicates\n",
        "print(f\"Shape After Removing Duplicates: {df_cleaned.shape}\")\n",
        "\n",
        "# Save the final cleaned dataset\n",
        "df_cleaned.to_csv(\"final_cleaned_data_no_duplicates.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows\n",
        "print(\"\\nFirst 5 Records After Removing Duplicates:\\n\", df_cleaned.head())\n"
      ],
      "metadata": {
        "id": "SYVwALB0W8-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding**"
      ],
      "metadata": {
        "id": "KAPhcyCMWBo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the cleaned dataset without duplicates\n",
        "df_cleaned = pd.read_csv(\"final_cleaned_data_no_duplicates.csv\", dtype=str, low_memory=False)\n",
        "\n",
        "# Identify categorical columns (excluding the target column)\n",
        "categorical_cols = df_cleaned.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "\n",
        "# Apply Label Encoding to categorical columns\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for col in categorical_cols:\n",
        "    df_cleaned[col] = df_cleaned[col].astype(str)  # Ensure all values are strings\n",
        "    df_cleaned[col] = encoder.fit_transform(df_cleaned[col])\n",
        "\n",
        "# Save the encoded dataset\n",
        "df_cleaned.to_csv(\"final_encoded_data.csv\", index=False)\n",
        "\n",
        "# Display first 5 rows after encoding\n",
        "print(\"Encoding Completed Successfully!\")\n",
        "print(\"\\nFirst 5 Records After Encoding:\\n\", df_cleaned.head())\n",
        "\n",
        "# Display column data types\n",
        "print(\"\\nUpdated Column Data Types:\\n\", df_cleaned.dtypes)\n"
      ],
      "metadata": {
        "id": "63aX4SToX8gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Splitting**"
      ],
      "metadata": {
        "id": "NXzls0CxYN0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load datasets with low_memory=False to avoid dtype warnings\n",
        "true_df = pd.read_csv(\"/content/True.csv\", encoding='utf-8', low_memory=False)\n",
        "fake_df = pd.read_csv(\"/content/Fake.csv\", encoding='utf-8', low_memory=False)\n",
        "\n",
        "# # Print column names to check if required columns exist\n",
        "# print(\"True News Columns:\", true_df.columns)\n",
        "# print(\"Fake News Columns:\", fake_df.columns)\n",
        "\n",
        "# Define relevant columns (handle missing columns gracefully)\n",
        "columns_to_keep = ['title', 'text', 'subject', 'date']\n",
        "true_df = true_df[[col for col in columns_to_keep if col in true_df.columns]]\n",
        "fake_df = fake_df[[col for col in columns_to_keep if col in fake_df.columns]]\n",
        "\n",
        "# Add labels: 1 for Fake, 0 for Real\n",
        "fake_df[\"label\"] = 1\n",
        "true_df[\"label\"] = 0\n",
        "\n",
        "# Print original dataset sizes\n",
        "print(f\"Original Fake News Records: {len(fake_df)}\")\n",
        "print(f\"Original Real News Records: {len(true_df)}\")\n",
        "\n",
        "# Balance dataset by downsampling Fake news to match Real news count\n",
        "fake_df_balanced = resample(fake_df, replace=False, n_samples=len(true_df), random_state=42)\n",
        "\n",
        "# Merge both datasets and shuffle\n",
        "balanced_df = pd.concat([fake_df_balanced, true_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print balanced dataset size\n",
        "print(f\"\\nBalanced Dataset Size: {len(balanced_df)}\")\n",
        "print(balanced_df['label'].value_counts())  # Verify equal class distribution\n",
        "\n",
        "# Split dataset into Training (80%) and Testing (20%)\n",
        "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42, stratify=balanced_df[\"label\"])\n",
        "\n",
        "# Print training and testing set sizes\n",
        "print(f\"\\nTraining Set: {len(train_df)} records\")\n",
        "print(f\"Testing Set: {len(test_df)} records\")\n",
        "\n",
        "# Save the balanced dataset (Optional)\n",
        "train_df.to_csv(\"train_data.csv\", index=False)\n",
        "test_df.to_csv(\"test_data.csv\", index=False)\n",
        "\n",
        "print(\"\\nDataset processing complete!\")\n"
      ],
      "metadata": {
        "id": "p39ezwCIB0yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Implementation**"
      ],
      "metadata": {
        "id": "_KWQNoHJwi3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install deap"
      ],
      "metadata": {
        "id": "QcH6AcQ3OHh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "lP_VOT5SOKnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = pd.read_csv('/content/Fake.csv')\n",
        "true = pd.read_csv('/content/True.csv')"
      ],
      "metadata": {
        "id": "NlexBIFYONDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_sample = fake.sample(n=500, random_state=42)\n",
        "true_sample = true.sample(n=500, random_state=42)\n",
        "\n",
        "fake_sample['label'] = 0\n",
        "true_sample['label'] = 1\n",
        "\n",
        "data = pd.concat([fake_sample, true_sample]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "truyAcy8OPTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['title'] = data['title'].fillna('')\n",
        "data['text'] = data['text'].fillna('')\n",
        "\n",
        "# Combine title and text\n",
        "data['text'] = data['title'] + ' ' + data['text']\n",
        "\n",
        "# Lowercasing\n",
        "def preprocess(text):\n",
        "    return text.lower()\n",
        "\n",
        "data['text'] = data['text'].apply(preprocess)"
      ],
      "metadata": {
        "id": "MyJ1xnPoOR8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "embeddings = np.vstack([get_embedding(text) for text in data['text']])"
      ],
      "metadata": {
        "id": "O83ywlBtOT6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=50)\n",
        "pca_embeddings = pca.fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "EWDpgT1JOV4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(pca_embeddings, data['label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_dN8Wx9UOY3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_individual(individual):\n",
        "    if sum(individual) == 0:\n",
        "        return 0,\n",
        "    selected_features = [index for index, bit in enumerate(individual) if bit == 1]\n",
        "    X_selected = X_train[:, selected_features]\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_selected, y_train)\n",
        "    predictions = clf.predict(X_selected)\n",
        "    return accuracy_score(y_train, predictions),\n"
      ],
      "metadata": {
        "id": "LlCQHiCJOalF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train.shape[1]\n",
        "\n",
        "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attr_bool', random.randint, 0, 1)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register('evaluate', eval_individual)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)"
      ],
      "metadata": {
        "id": "ucLIYm3KOdY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population = toolbox.population(n=20)\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=True)"
      ],
      "metadata": {
        "id": "PnAYxgv2Of9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "selected_features = [index for index, bit in enumerate(best_individual) if bit == 1]\n",
        "\n",
        "# Test classifier with selected features\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train[:, selected_features], y_train)\n",
        "y_pred = clf.predict(X_test[:, selected_features])\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "isbwbOPxOh3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define population and statistics\n",
        "population = toolbox.population(n=20)\n",
        "hof = tools.HallOfFame(1)\n",
        "stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "stats.register('max', np.max)\n",
        "stats.register('avg', np.mean)\n",
        "\n",
        "# Run GA\n",
        "population, logbook = algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2,\n",
        "                                          ngen=20, stats=stats, halloffame=hof, verbose=True)\n",
        "\n",
        "# Extract stats\n",
        "gen = logbook.select(\"gen\")\n",
        "max_fitness = logbook.select(\"max\")\n",
        "avg_fitness = logbook.select(\"avg\")\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(gen, max_fitness, label='Max Fitness', marker='o')\n",
        "plt.plot(gen, avg_fitness, label='Average Fitness', marker='x')\n",
        "plt.xlabel(\"Generation\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"GA Feature Selection: Accuracy over Generations\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0nI4YsaaOvOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code**"
      ],
      "metadata": {
        "id": "2_cL3CC5OsyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!pip install transformers\n",
        "!pip install deap\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Step 1: Load Dataset (Assuming you have uploaded the datasets in Colab)\n",
        "fake = pd.read_csv('/content/Fake.csv')\n",
        "true = pd.read_csv('/content/True.csv')\n",
        "\n",
        "# Step 2: Balance the dataset (500 Fake + 500 True)\n",
        "fake_sample = fake.sample(n=500, random_state=42)\n",
        "true_sample = true.sample(n=500, random_state=42)\n",
        "data = pd.concat([fake_sample, true_sample]).reset_index(drop=True)\n",
        "\n",
        "fake_sample['label'] = 0\n",
        "true_sample['label'] = 1\n",
        "\n",
        "# Now concatenate\n",
        "data = pd.concat([fake_sample, true_sample]).reset_index(drop=True)\n",
        "\n",
        "# Step 3: Text Preprocessing (keep it simple)\n",
        "\n",
        "# Handle missing values\n",
        "data['title'] = data['title'].fillna('')\n",
        "data['text'] = data['text'].fillna('')\n",
        "\n",
        "# Combine title and text\n",
        "data['text'] = data['title'] + ' ' + data['text']\n",
        "\n",
        "# Lowercase\n",
        "def preprocess(text):\n",
        "    return text.lower()\n",
        "\n",
        "data['text'] = data['text'].apply(preprocess)\n",
        "\n",
        "# Step 4: BERT Embeddings (using DistilBERT)\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Function to get embeddings\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "embeddings = np.vstack([get_embedding(text) for text in data['text']])\n",
        "\n",
        "# Step 5: Apply PCA\n",
        "pca = PCA(n_components=50)\n",
        "pca_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Step 6: Genetic Algorithm for Feature Selection\n",
        "# Define fitness function\n",
        "def eval_individual(individual):\n",
        "    if sum(individual) == 0:\n",
        "        return 0,\n",
        "    selected_features = [index for index, bit in enumerate(individual) if bit == 1]\n",
        "    X_selected = X_train[:, selected_features]\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_selected, y_train)\n",
        "    predictions = clf.predict(X_selected)\n",
        "    return accuracy_score(y_train, predictions),\n",
        "\n",
        "# Prepare data for GA\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_embeddings, data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "creator.create('FitnessMax', base.Fitness, weights=(1.0,))\n",
        "creator.create('Individual', list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register('attr_bool', random.randint, 0, 1)\n",
        "toolbox.register('individual', tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
        "toolbox.register('population', tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register('evaluate', eval_individual)\n",
        "toolbox.register('mate', tools.cxTwoPoint)\n",
        "toolbox.register('mutate', tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register('select', tools.selTournament, tournsize=3)\n",
        "\n",
        "population = toolbox.population(n=20)\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=False)\n",
        "\n",
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "selected_features = [index for index, bit in enumerate(best_individual) if bit == 1]\n",
        "\n",
        "# Step 7: Train final model with selected features\n",
        "X_train_selected = X_train[:, selected_features]\n",
        "X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_selected, y_train)\n",
        "predictions = clf.predict(X_test_selected)\n",
        "\n",
        "# Step 8: Evaluation\n",
        "print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
      ],
      "metadata": {
        "id": "HK1QKj9pbq5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the best individual on test data\n",
        "\n",
        "# Get the best individual\n",
        "best_individual = tools.selBest(population, k=1)[0]\n",
        "selected_features = [index for index, bit in enumerate(best_individual) if bit == 1]\n",
        "\n",
        "# Check if at least one feature is selected\n",
        "if selected_features:\n",
        "    X_train_selected = X_train[:, selected_features]\n",
        "    X_test_selected = X_test[:, selected_features]\n",
        "\n",
        "    # Train final classifier\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train_selected, y_train)\n",
        "    predictions = clf.predict(X_test_selected)\n",
        "\n",
        "    # Evaluate\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
        "    print(\"Accuracy Score:\", accuracy_score(y_test, predictions))\n",
        "else:\n",
        "    print(\"No features were selected by the genetic algorithm.\")\n"
      ],
      "metadata": {
        "id": "tphPHl_ZMyYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "mWb8tXS-M8n7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['text_length'] = data['text'].apply(len)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(data['text_length'], bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Text Lengths')\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4EU2DzV2M-Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', color='green')\n",
        "plt.title('PCA Explained Variance')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "psPemCrnNA49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Train on selected features\n",
        "selected_features = [index for index, bit in enumerate(best_individual) if bit == 1]\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train[:, selected_features], y_train)\n",
        "y_pred = clf.predict(X_test[:, selected_features])\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xvV8CqIxNHCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitness_history = []\n",
        "\n",
        "def record_fitness(population):\n",
        "    fits = [ind.fitness.values[0] for ind in population]\n",
        "    fitness_history.append(max(fits))\n",
        "\n",
        "# Run GA with logging\n",
        "for gen in range(10):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    record_fitness(population)\n",
        "\n",
        "# Plot fitness history\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fitness_history, marker='o', linestyle='--', color='purple')\n",
        "plt.title('Genetic Algorithm Fitness Over Generations')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Best Fitness (Accuracy)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QGfL4QCfNMXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitness_history = []\n",
        "\n",
        "def record_fitness(population):\n",
        "    fits = [ind.fitness.values[0] for ind in population]\n",
        "    fitness_history.append(max(fits))\n",
        "\n",
        "# Run GA with logging\n",
        "for gen in range(10):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    record_fitness(population)\n",
        "\n",
        "# Plot fitness history\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fitness_history, marker='o', linestyle='--', color='purple')\n",
        "plt.title('Genetic Algorithm Fitness Over Generations')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Best Fitness (Accuracy)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WBirWDc_x2uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitness_history = []\n",
        "\n",
        "def record_fitness(population):\n",
        "    fits = [ind.fitness.values[0] for ind in population]\n",
        "    fitness_history.append(max(fits))\n",
        "\n",
        "# Run GA with logging\n",
        "for gen in range(10):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    record_fitness(population)\n",
        "\n",
        "# Plot fitness history\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fitness_history, marker='o', linestyle='--', color='purple')\n",
        "plt.title('Genetic Algorithm Fitness Over Generations')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Best Fitness (Accuracy)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XuotRXuTx3cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitness_history = []\n",
        "\n",
        "def record_fitness(population):\n",
        "    fits = [ind.fitness.values[0] for ind in population]\n",
        "    fitness_history.append(max(fits))\n",
        "\n",
        "# Run GA with logging\n",
        "for gen in range(10):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    record_fitness(population)\n",
        "\n",
        "# Plot fitness history\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fitness_history, marker='o', linestyle='--', color='purple')\n",
        "plt.title('Genetic Algorithm Fitness Over Generations')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Best Fitness (Accuracy)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xq8dgSZMx-56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fitness_history = []\n",
        "\n",
        "def record_fitness(population):\n",
        "    fits = [ind.fitness.values[0] for ind in population]\n",
        "    fitness_history.append(max(fits))\n",
        "\n",
        "# Run GA with logging\n",
        "for gen in range(10):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, k=len(population))\n",
        "    record_fitness(population)\n",
        "\n",
        "# Plot fitness history\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fitness_history, marker='o', linestyle='--', color='purple')\n",
        "plt.title('Genetic Algorithm Fitness Over Generations')\n",
        "plt.xlabel('Generation')\n",
        "plt.ylabel('Best Fitness (Accuracy)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3RWnjJudyGsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Data from the table\n",
        "data = {\n",
        "    'Class': ['Fake news', 'Real news'],\n",
        "    'Precision': [0.98, 0.97],\n",
        "    'Recall': [0.97, 0.98],\n",
        "    'F1-Score': [0.97, 0.98],\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index('Class', inplace=True)\n",
        "\n",
        "# Plotting\n",
        "ax = df.plot(kind='bar', figsize=(8, 6))\n",
        "plt.title('Classification Metrics for Fake News Detection')\n",
        "plt.ylabel('Score')\n",
        "plt.ylim(0.95, 1.00)\n",
        "plt.xticks(rotation=0)\n",
        "plt.legend(title='Metric')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "35ln4E3hRYp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Predict probabilities for test set\n",
        "y_probs = clf.predict_proba(X_test_selected)[:, 1]  # Probability of class 1 (Real news)\n",
        "\n",
        "# Calculate FPR, TPR\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plotting the ROC Curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line\n",
        "\n",
        "# Custom axis labels\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (Fake news predicted as Real)', fontsize=12)\n",
        "plt.ylabel('True Positive Rate (Real news predicted as Real)', fontsize=12)\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=14)\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LUa_I2XqvSIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = [\"Fake\", \"Real\"]\n",
        "\n",
        "# Create heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix Heatmap\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "K_ocF56gxzRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "\n",
        "# Define performance metrics for different configurations\n",
        "data = {\n",
        "    'Configuration': [\n",
        "        'Full Model (DistilBERT + PCA + GA)',\n",
        "        'DistilBERT + PCA',\n",
        "        'DistilBERT Only'\n",
        "    ],\n",
        "    'Accuracy': [0.975, 0.952, 0.931],\n",
        "    'Precision': [0.98, 0.96, 0.93],\n",
        "    'Recall': [0.97, 0.95, 0.92],\n",
        "    'F1 Score': [0.975, 0.955, 0.925]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Wrap long x-axis labels\n",
        "df['Configuration'] = df['Configuration'].apply(lambda x: '\\n'.join(textwrap.wrap(x, 25)))\n",
        "\n",
        "# Melt for seaborn barplot\n",
        "df_melted = df.melt(id_vars='Configuration', var_name='Metric', value_name='Score')\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_melted, x='Configuration', y='Score', hue='Metric', palette='Set2')\n",
        "\n",
        "plt.title(\"Model Performance\", fontsize=14)\n",
        "plt.ylim(0.9, 1.0)\n",
        "plt.xticks(rotation=0, ha='center', fontsize=10)\n",
        "plt.ylabel(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.legend(title='Metric', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ofZRM8f-yqEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "\n",
        "# Define performance metrics for different configurations\n",
        "data = {\n",
        "    'Configuration': [\n",
        "        'Full Model (DistilBERT + PCA + GA)',\n",
        "        'DistilBERT + PCA',\n",
        "        'DistilBERT Only'\n",
        "    ],\n",
        "    'Accuracy': [0.975, 0.952, 0.931],\n",
        "    'Precision': [0.98, 0.96, 0.93],\n",
        "    'Recall': [0.97, 0.95, 0.92],\n",
        "    'F1 Score': [0.975, 0.955, 0.925]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Wrap long x-axis labels\n",
        "df['Configuration'] = df['Configuration'].apply(lambda x: '\\n'.join(textwrap.wrap(x, 25)))\n",
        "\n",
        "# Set plot style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
        "\n",
        "# Plot separate barplots for each metric\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.barplot(data=df, x='Configuration', y=metric, palette='PuRd')\n",
        "    plt.title(f'Model Comparison - {metric}', fontsize=14)\n",
        "    plt.ylim(0.9, 1.0)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel('Model')\n",
        "    plt.xticks(rotation=0, ha='center', fontsize=10)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "aUfaq3-WzTop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final**"
      ],
      "metadata": {
        "id": "OfljGo1XU0nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers deap gradio joblib"
      ],
      "metadata": {
        "id": "dqXp2gu_VB_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages if needed\n",
        "!pip install transformers deap gradio\n",
        "\n",
        "# === IMPORTS ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from deap import base, creator, tools, algorithms\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# === STEP 1: LOAD AND PREPROCESS DATA ===\n",
        "fake = pd.read_csv('/content/Fake.csv')\n",
        "true = pd.read_csv('/content/True.csv')\n",
        "\n",
        "fake_sample = fake.sample(n=500, random_state=42)\n",
        "true_sample = true.sample(n=500, random_state=42)\n",
        "\n",
        "fake_sample['label'] = 0\n",
        "true_sample['label'] = 1\n",
        "\n",
        "data = pd.concat([fake_sample, true_sample]).reset_index(drop=True)\n",
        "data['title'] = data['title'].fillna('')\n",
        "data['text'] = data['text'].fillna('')\n",
        "data['text'] = (data['title'] + ' ' + data['text']).str.lower()\n",
        "\n",
        "# === STEP 2: BERT EMBEDDINGS ===\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "print(\"Generating BERT embeddings...\")\n",
        "embeddings = np.vstack([get_embedding(t) for t in data['text']])\n",
        "\n",
        "# === STEP 3: PCA REDUCTION ===\n",
        "pca = PCA(n_components=50)\n",
        "pca_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# === STEP 4: GENETIC ALGORITHM FEATURE SELECTION ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_embeddings, data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "def eval_individual(ind):\n",
        "    if sum(ind) == 0:\n",
        "        return 0.,\n",
        "    selected = [i for i, bit in enumerate(ind) if bit == 1]\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train[:, selected], y_train)\n",
        "    preds = clf.predict(X_train[:, selected])\n",
        "    return accuracy_score(y_train, preds),\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"evaluate\", eval_individual)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "print(\"Running Genetic Algorithm...\")\n",
        "population = toolbox.population(n=20)\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=False)\n",
        "\n",
        "best = tools.selBest(population, k=1)[0]\n",
        "selected_features = [i for i, bit in enumerate(best) if bit == 1]\n",
        "\n",
        "# === STEP 5: FINAL MODEL TRAINING ===\n",
        "X_train_sel = X_train[:, selected_features]\n",
        "X_test_sel = X_test[:, selected_features]\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_sel, y_train)\n",
        "preds = clf.predict(X_test_sel)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n",
        "\n",
        "# === STEP 6: GRADIO APP===\n",
        "def classify_news(text):\n",
        "    text = text.lower()\n",
        "    embedding = get_embedding(text)\n",
        "    reduced = pca.transform([embedding])\n",
        "    selected = reduced[:, selected_features]\n",
        "    pred = clf.predict(selected)[0]\n",
        "    return \"Fake News\" if pred == 0 else \"Real News\"\n",
        "\n",
        "iface = gr.Interface(fn=classify_news,\n",
        "                     inputs=gr.Textbox(lines=5, placeholder=\"Enter news article title and content...\"),\n",
        "                     outputs=\"text\",\n",
        "                     title=\"Fake News Detection\",\n",
        "                     description=\"Enter a news article and the model will predict whether it's real or fake.\")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "G8EFlKmJUzvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import gradio as gr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from deap import base, creator, tools, algorithms\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "qECFnII_X9wH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = pd.read_csv('/content/Fake.csv')\n",
        "true = pd.read_csv('/content/True.csv')\n",
        "\n",
        "fake_sample = fake.sample(n=500, random_state=42)\n",
        "true_sample = true.sample(n=500, random_state=42)\n",
        "\n",
        "fake_sample['label'] = 0\n",
        "true_sample['label'] = 1\n",
        "\n",
        "data = pd.concat([fake_sample, true_sample]).reset_index(drop=True)\n",
        "data['title'] = data['title'].fillna('')\n",
        "data['text'] = data['text'].fillna('')\n",
        "data['text'] = (data['title'] + ' ' + data['text']).str.lower()\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "x5Y4OW-GYAi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 2: DistilBERT EMBEDDINGS ===\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = AutoModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "def get_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "print(\"Generating BERT embeddings...\")\n",
        "embeddings = np.vstack([get_embedding(t) for t in data['text']])\n",
        "\n",
        "# Display a few original embeddings\n",
        "print(\"\\nSample DistilBERT Embedding Vectors (first 3 samples):\")\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\", embeddings[i][:10], \"...\")  # Show first 10 dimensions"
      ],
      "metadata": {
        "id": "gq6kaaN9YEW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 3: PCA REDUCTION ===\n",
        "pca = PCA(n_components=50)\n",
        "pca_embeddings = pca.fit_transform(embeddings)\n",
        "\n",
        "# Display PCA-reduced vectors\n",
        "print(\"\\nSample PCA-Reduced Vectors (first 3 samples):\")\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\", pca_embeddings[i][:10], \"...\")  # Show first 10 components\n"
      ],
      "metadata": {
        "id": "lxpMu5sfYHVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 4: GENETIC ALGORITHM FEATURE SELECTION ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(pca_embeddings, data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "def eval_individual(ind):\n",
        "    if sum(ind) == 0:\n",
        "        return 0.,\n",
        "    selected = [i for i, bit in enumerate(ind) if bit == 1]\n",
        "    clf = LogisticRegression(max_iter=1000)\n",
        "    clf.fit(X_train[:, selected], y_train)\n",
        "    preds = clf.predict(X_train[:, selected])\n",
        "    return accuracy_score(y_train, preds),\n",
        "\n",
        "num_features = X_train.shape[1]\n",
        "\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=num_features)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"evaluate\", eval_individual)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "print(\"Running Genetic Algorithm...\")\n",
        "population = toolbox.population(n=20)\n",
        "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=10, verbose=False)\n",
        "\n",
        "best = tools.selBest(population, k=1)[0]\n",
        "selected_features = [i for i, bit in enumerate(best) if bit == 1]\n",
        "\n",
        "# Show selected feature indices\n",
        "print(\"\\nSelected Feature Indices by Genetic Algorithm:\", selected_features)\n",
        "\n",
        "# Apply GA selection to a few PCA vectors\n",
        "print(\"\\nSample Vectors After GA Feature Selection (first 3 samples):\")\n",
        "X_pca_selected = X_train[:, selected_features]\n",
        "for i in range(3):\n",
        "    print(f\"Sample {i+1}:\", X_pca_selected[i])"
      ],
      "metadata": {
        "id": "YWdAX-07YKj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 5: FINAL MODEL TRAINING ===\n",
        "X_train_sel = X_train[:, selected_features]\n",
        "X_test_sel = X_test[:, selected_features]\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_sel, y_train)\n",
        "preds = clf.predict(X_test_sel)\n",
        "\n",
        "print(\"Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, preds))\n"
      ],
      "metadata": {
        "id": "Hv4U4IEoYN_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === STEP 6: GRADIO APP ===\n",
        "def classify_news(text):\n",
        "    text = text.lower()\n",
        "    embedding = get_embedding(text)\n",
        "    reduced = pca.transform([embedding])\n",
        "    selected = reduced[:, selected_features]\n",
        "    pred = clf.predict(selected)[0]\n",
        "    return \"Fake News\" if pred == 0 else \"Real News\"\n",
        "\n",
        "iface = gr.Interface(fn=classify_news,\n",
        "                     inputs=gr.Textbox(lines=5, placeholder=\"Enter news article title and content...\"),\n",
        "                     outputs=\"text\",\n",
        "                     title=\"Fake News Detection\",\n",
        "                     description=\"Enter a news article and the model will predict whether it's real or fake.\")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "I4v2m4kOYQgW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "iaTs9w91J1wN",
        "9QiskUgtXC4k",
        "_KWQNoHJwi3y",
        "2_cL3CC5OsyL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}